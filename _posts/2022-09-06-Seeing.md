---
title: Seeing
tags: AI Neurology Art
article_header:
  type: cover
  image:
    src: /screenshot.jpg
---
TEST
A Post with Header Image, See [Page layout](https://tianqi.name/jekyll-TeXt-theme/samples.html#page-layout) for more examples.
jghkhvjhvjhvjh


## Intro
  there’s some amazing work being done with AI, and with scale more and more problems appear to be solve-able. Here’s what some of that looks like
There’s a back and forth in AI, about what the trajectory of current progress looks like. You have people (who?) saying we’re in an AI winter, and a winter where we’ve picked all the low hanging fruit (chollet, lex friedman?). We have another camp throwing more and more compute at the problem enabled by architectures like attention and the availability of ever more data (and methods for handling that data (leave this in) ). This approach has led to astounding results in a variety of hard problems. We have GATO from deepmind applying a large transformer scaling approach over it’s more traditional RL. OpenAI perhaps represents the very best of this approach, and many of the claims about scaling laws originate from this world class lab(check, provide source). We have incredibly impressive large language models like GPT3, their use in what is effectively program synthesis from natural language with CODEX (and available as github co-pilot), amazing classification performance and utility of CLIP, which leads us to the news now. 

DALLE-2. It is what made this. This is beautiful. 
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">This was made using the DALLE-2 neural network to extend Michaelangelo&#39;s creation of Adam. <a href="https://t.co/sIfTEjXgwO">pic.twitter.com/sIfTEjXgwO</a></p>&mdash; Far Left Kyle (@FLKDayton) <a href="https://twitter.com/FLKDayton/status/1543261364315193346?ref_src=twsrc%5Etfw">July 2, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
<!--add more to really get across the point--> 
This is also Dalle. 
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Some people sell AI for grading essays and sorting resumes. Imagine how wrong it must quietly, constantly, be. <a href="https://t.co/KRuaacYHAo">https://t.co/KRuaacYHAo</a></p>&mdash; Janelle Shane (@JanelleCShane) <a href="https://twitter.com/JanelleCShane/status/1526225473272938501?ref_src=twsrc%5Etfw">May 16, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

## Quietly Wrong
Janelle Shane runs an excellent blog I was recently introduced to, collecting a variety of examples of… well, weird AI. This ‘weirdness’ is well known and taken at varying levels of seriousness by the many practitioners, researchers, and sellers (change to providers?) of AI systems. The grab bag of AI systems are vulnerable to the grab bag of biases and weirdness. After all, if there is a flawed but useful pattern, an un-truth, it can (and most often will) be picked up on. 

| ![Suprious Correlations](/assets/images/first_blog/chart_soy.png) |
|:--:|
| *Perhaps we should stop subsidizing soy? Afterall it's 99% correlated* [![Spurious Correlations](https://www.tylervigen.com/spurious-correlations)](https://www.tylervigen.com/spurious-correlations) |

The untruth could be a curiosity like that. It could recommend the right course of action, if for the wrong reasons. Or it could dig up the corpse of Jim Crow, puppeting its bones. Of particular importance are deep learning systems not just for their ‘quietness’ but very real power, and resulting popularity. Maybe even more than that, is their fascinating weirdness. 

Now, I can’t say whether I’m hot or cold on deep learning. These systems will absolutely have a role in humanities’ future, and should. They can do such amazing things. More than that, they are beautiful. What can be made is visually striking and regardless of whether you’d deem it art or not it is visually striking. 
Dalle2 is not particularly special, we have Dalle 1 (which under the hood is very different model


| ![Dalle 1 Cats](/assets/images/first_blog/Dalle1.png) |
|:--:|
| *Dalle 1 producing weird Cats* [![Open AI's Dalle 1](https://openai.com/blog/dall-e/)](https://openai.com/blog/dall-e/)  |

| ![Dalle 1 Cats](/assets/images/first_blog/disco_diff.webp) |
|:--:|
| *A Disco Diffusion image from reddit user komoro* [![Reddit page](https://www.reddit.com/r/DiscoDiffusion/comments/vyeumc/im_not_entirely_sure_why_it_escalated_into_this/)](https://www.reddit.com/r/DiscoDiffusion/comments/vyeumc/im_not_entirely_sure_why_it_escalated_into_this/)  |

| ![Wombo AI](/assets/images/first_blog/wombo.png){: width="250" } |
|:--:|
| *Wombo AI which at the time used Open AI's CLIP and VQ-GAN* [![ try Wombo AI](https://www.wombo.art)](https://www.wombo.art/)  |

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Caucasian man with somewhat exaggerated features looking sceptically at the viewer, <a href="https://twitter.com/hashtag/art?src=hash&amp;ref_src=twsrc%5Etfw">#art</a> made with <a href="https://twitter.com/hashtag/Artbreeder?src=hash&amp;ref_src=twsrc%5Etfw">#Artbreeder</a>.<a href="https://t.co/3fs8suGMsX">https://t.co/3fs8suGMsX</a> <a href="https://t.co/mxlhHNprnf">pic.twitter.com/mxlhHNprnf</a></p>&mdash; Gniwu (@gniwukiwi) <a href="https://twitter.com/gniwukiwi/status/1545474647713611781?ref_src=twsrc%5Etfw">July 8, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

Last is ArtBreeder (Based on PicBreeder and NEAT by the excellent AI researcher Kennth Stannely ). Now compare ArtBreeder, which is much much older (at least in terms of AI technology) but still gets pretty damn good results. Yes, these are cherry picked but maybe even more than you may realize. You see, Artbreeder uses large groups of humans (the users) to make decisions about what kinds of images to produce in a feedback loop determining which images are slightly morphed and presented next round. 

Naively you might expect humans to randomly select paths
through this abstract image space. Less naively, you might expect the search behavior to aggregate around some kind of average behavior.
But you see, what we see is so totally different from what’s in front of you. People see faces, dragons, and telephones in clouds. They don’t see vaporized water molecules. They don’t see atoms. They don’t see climate patterns. We perceive at a certain scale and even more we filter out what we do not prefer, seek what we do, ignore what does not align with our goals, and force it into our internal narrative.
Flawed process that it is, it pulls this 

| ![Art Breeder](/assets/images/first_blog/artbredland.png) |
| *A  "bred" series of landscapes* [![ try ArtBreeder](https://www.artbreeder.com/beta/image/ca8a30f25395cceb7e930da01aa2)](https://www.artbreeder.com/beta/image/ca8a30f25395cceb7e930da01aa2)  |

from this

| ![BigGan](/assets/images/first_blog/bigganland.png) |
|:--:|
| *One Of ArtBreeder's Underlying Models BigGAN* [![ BigGAN and Weird AI](https://www.aiweirdness.com/imaginary-worlds-dreamed-by-biggan-18-09-30/)](https://www.aiweirdness.com/imaginary-worlds-dreamed-by-biggan-18-09-30/)  |

If you don’t believe me, I can’t recommend playing around with it yourself enough. With your strange, flawed, and weird way of looking at the world, you can see stuff. Whole and coherent objects from the cacophonous orchestra of all reality, all the time, at all scales things appear before you with as little effort as you use to breathe.
Whereas an AI can see the world like this: 

| ![BigGan](/assets/images/first_blog/biganWrong.png) |
|:--:|
| *A BigGAN image, can you see anything here?* [![ BigGAN and Weird AI](https://www.aiweirdness.com/imaginary-worlds-dreamed-by-biggan-18-09-30/)](https://www.aiweirdness.com/imaginary-worlds-dreamed-by-biggan-18-09-30/)  |

I  would recommend spending some more time looking at the previous images. If you look closely at details like faces, boundaries, foreground-background distinction, you’ll notice things are just slightly wrong (sometimes more than slightly), sometimes obfuscated as paint strokes or other artistic flourishes. In a variety of models, made in a variety of different ways, with different generation seeds, with different purposes I think you will notice a shadow of the same wrongness apparent in this image.

Now, I did somewhat mislead you earlier. In fact, only part of you sees stuff, and other parts see other (equally important) aspects of reality. Looking into these parts can help us start  to understand this big mess, and maybe how to start getting us out of it. 








<!--more-->
