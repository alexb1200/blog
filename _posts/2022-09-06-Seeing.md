---
title: Seeing Wittgenstien's Ghost in the Machine
tags: AI Neurology Art
article_header:
  type: cover
  image:
    src: /duckEdit.jpg
---
Sooner or later AI is gonna rule the world. But it's not terminator we should be worried about. It may end the world without ever seeing it.  
## Intro
There’s some amazing work being done with AI, and with scale more and more problems appear to be solve-able. Here’s what some of that looks like
There’s a back and forth in AI, about what the trajectory of current progress looks like. You have people  [![people](https://www.bbc.com/news/technology-51064369)](https://www.bbc.com/news/technology-51064369)  saying we’re in an AI winter, and a winter where we’ve picked all the low hanging fruit [![ (chollet, lex friedman )](https://www.youtube.com/watch?v=PUAdj3w3wO4)](https://www.youtube.com/watch?v=PUAdj3w3wO4) . We have another camp throwing more and more compute at the problem enabled by architectures like attention and the availability of ever more data (and methods for handling that data ). This approach has led to astounding results in a variety of hard problems. We have GATO from deepmind applying a large transformer scaling approach over more traditional RL methods. OpenAI perhaps represents the very best of this , and many of the claims about scaling laws originate from this world class lab(check, provide source). We have incredibly impressive large language models like GPT3, their use in what is effectively program synthesis from natural language with CODEX (and available as github co-pilot), amazing classification performance and utility of CLIP, which leads us to the news now. 

DALLE-2. It is what made this. This is beautiful. 
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">This was made using the DALLE-2 neural network to extend Michaelangelo&#39;s creation of Adam. <a href="https://t.co/sIfTEjXgwO">pic.twitter.com/sIfTEjXgwO</a></p>&mdash; Far Left Kyle (@FLKDayton) <a href="https://twitter.com/FLKDayton/status/1543261364315193346?ref_src=twsrc%5Etfw">July 2, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
<!--add more to really get across the point--> 
This is also Dalle. 
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Some people sell AI for grading essays and sorting resumes. Imagine how wrong it must quietly, constantly, be. <a href="https://t.co/KRuaacYHAo">https://t.co/KRuaacYHAo</a></p>&mdash; Janelle Shane (@JanelleCShane) <a href="https://twitter.com/JanelleCShane/status/1526225473272938501?ref_src=twsrc%5Etfw">May 16, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

## Quietly Wrong
Janelle Shane runs an excellent blog I was recently introduced to, collecting a variety of examples of… well, weird AI. This ‘weirdness’ is well known and taken at varying levels of seriousness by the many practitioners, researchers, and sellers (change to providers?) of AI systems. The grab bag of AI systems are vulnerable to the grab bag of biases and weirdness. After all, if there is a flawed but useful pattern, an un-truth, it can (and most often will) be picked up on. 

| ![Suprious Correlations]( {{ "/assets/images/firstBlog/chartsoy.png" | relative_url }} ) |
|:--:|
| *Perhaps we should stop subsidizing soy? Afterall it's 99% correlated* [![Spurious Correlations](https://www.tylervigen.com/spurious-correlations)](https://www.tylervigen.com/spurious-correlations) |

The untruth could be a curiosity like that. It could recommend the right course of action, if for the wrong reasons. Or it could dig up the corpse of Jim Crow, puppeting its bones. Of particular importance are deep learning systems not just for their ‘quietness’ but very real power, and resulting popularity. Maybe even more than that, is their fascinating weirdness. 

Now, I can’t say whether I’m hot or cold on deep learning. These systems will absolutely have a role in humanities’ future, and should. They can do such amazing things. More than that, they are beautiful. What can be made is visually striking and regardless of whether you’d deem it art or not it is visually striking. 
Dalle2 is not particularly special, we have Dalle 1 (which under the hood is very different model


| ![Dalle 1 Cats]({{ "/assets/images/firstBlog/Dalle1.png" | relative_url }}) |
|:--:|
| *Dalle 1 producing weird Cats* [![Open AI's Dalle 1](https://openai.com/blog/dall-e/)](https://openai.com/blog/dall-e/)  |

| ![Disco Diffusion]({{ "/assets/images/firstBlog/discodDiff.webp" | relative_url }} ) |
|:--:|
| *A Disco Diffusion image from reddit user komoro* [![Reddit page](https://www.reddit.com/r/DiscoDiffusion/comments/vyeumc/im_not_entirely_sure_why_it_escalated_into_this/)](https://www.reddit.com/r/DiscoDiffusion/comments/vyeumc/im_not_entirely_sure_why_it_escalated_into_this/)  |

| ![Wombo AI]({{ "/assets/images/firstBlog/wombo.png" | relative_url }}){: width="250" } |
|:--:|
| *Wombo AI which at the time used Open AI's CLIP and VQ-GAN* [![ try Wombo AI](https://www.wombo.art)](https://www.wombo.art/)  |

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Caucasian man with somewhat exaggerated features looking sceptically at the viewer, <a href="https://twitter.com/hashtag/art?src=hash&amp;ref_src=twsrc%5Etfw">#art</a> made with <a href="https://twitter.com/hashtag/Artbreeder?src=hash&amp;ref_src=twsrc%5Etfw">#Artbreeder</a>.<a href="https://t.co/3fs8suGMsX">https://t.co/3fs8suGMsX</a> <a href="https://t.co/mxlhHNprnf">pic.twitter.com/mxlhHNprnf</a></p>&mdash; Gniwu (@gniwukiwi) <a href="https://twitter.com/gniwukiwi/status/1545474647713611781?ref_src=twsrc%5Etfw">July 8, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

Last is ArtBreeder (Based on PicBreeder and NEAT by the excellent AI researcher Kennth Stannely ). Now compare ArtBreeder, which is much much older (at least in terms of AI technology) but still gets pretty damn good results. Yes, these are cherry picked but maybe even more than you may realize. You see, Artbreeder uses large groups of humans (the users) to make decisions about what kinds of images to produce in a feedback loop determining which images are slightly morphed and presented next round. 

Naively you might expect humans to randomly select paths
through this abstract image space. Less naively, you might expect the search behavior to aggregate around some kind of average behavior.
But you see, what we see is so totally different from what’s in front of you. People see faces, dragons, and telephones in clouds. They don’t see vaporized water molecules. They don’t see atoms. They don’t see climate patterns. We perceive at a certain scale and even more we filter out what we do not prefer, seek what we do, ignore what does not align with our goals, and force it into our internal narrative.
Flawed process that it is, it pulls this 

| ![Art Breeder]({{ "/assets/images/firstBlog/artbredland.png" | relative_url }}) |
| *A  "bred" series of landscapes* [![ try ArtBreeder](https://www.artbreeder.com/beta/image/ca8a30f25395cceb7e930da01aa2)](https://www.artbreeder.com/beta/image/ca8a30f25395cceb7e930da01aa2)  |

from this

| ![BigGan]({{ "/assets/images/firstBlog/bigganland.PNG" | relative_url }}) |
|:--:|
| *One Of ArtBreeder's Underlying Models BigGAN* [![ BigGAN and Weird AI](https://www.aiweirdness.com/imaginary-worlds-dreamed-by-biggan-18-09-30/)](https://www.aiweirdness.com/imaginary-worlds-dreamed-by-biggan-18-09-30/)  |

If you don’t believe me, I can’t recommend playing around with it yourself enough. With your strange, flawed, and weird way of looking at the world, you can see stuff. Whole and coherent objects from the cacophonous orchestra of all reality, all the time, at all scales things appear before you with as little effort as you use to breathe.
Whereas an AI can see the world like this: 

| ![BigGan]({{ "/assets/images/firstBlog/biganWrong.png" | relative_url }}) |
|:--:|
| *A BigGAN image, can you see anything here?* [![ BigGAN and Weird AI](https://www.aiweirdness.com/imaginary-worlds-dreamed-by-biggan-18-09-30/)](https://www.aiweirdness.com/imaginary-worlds-dreamed-by-biggan-18-09-30/)  |

I  would recommend spending some more time looking at the previous images. If you look closely at details like faces, boundaries, foreground-background distinction, you’ll notice things are just slightly wrong (sometimes more than slightly), sometimes obfuscated as paint strokes or other artistic flourishes. In a variety of models, made in a variety of different ways, with different generation seeds, with different purposes I think you will notice a shadow of the same wrongness apparent in this image.

Now, I did somewhat mislead you earlier. In fact, only part of you sees stuff, and other parts see other (equally important) aspects of reality. Looking into these parts can help us start  to understand this big mess, and maybe how to start getting us out of it. 

## System 1 and System 2
Now I have a little riddle for you.
If you buy a ball and a bat from a sports store for $1.10, and the bat costs one dollar more than the ball, how much did the ball cost? 

Most people answer 10 cents. And of course if the bat were to cost a dollar more, it would cost $1.10. So together they would cost $1.20 which unfortunately is not $1.10. 

| ![A Tragedy]({{ "/assets/images/firstBlog/base.png" | relative_url }}){: width= "250"} |
|:--:|
| *I know I have no shame.*   |

[![Youre welcome to try another riddle](https://www.considerable.com/life/education/difficult-straightforward-word-problem/)](https://www.considerable.com/life/education/difficult-straightforward-word-problem/)

Nobel prize winning economist Danial Kahnmann attributes this mistake to something called system 1, and conversely if you answered 5 cents to system 2. This dichotomy is an abstraction placed on top of the brain, not pointing to any specific function or part, which describes overall modes of cognition. Fundamentally system 1 is fast, intuitive, automatic, and has a broad attention(find other word). In contrast, system 2 is slow, deliberate, and has a specific attention. Kahnmann identified this distinction as part of his larger research dealing with human decision making, that is rationality (and often irrationality), in economics. His contributions include coining the term cognitive bias. 

It would be a mistake to say that we should aspire to exclusively interact with the world using our type 2 system. Both are necessary, and what we see as grace when a tennis player moves to fluidly hit the ball, or a painter's rapid rendering of a form is mediated by system 1. It’s about using  each where they belong, and so while we may need more of system 2, it’s not as though we could do without system 1 altogether. 

For some time AI researchers (like [![Yoshua Bengio](https://bdtechtalks.com/2019/12/23/yoshua-bengio-neurips-2019-deep-learning/)](https://bdtechtalks.com/2019/12/23/yoshua-bengio-neurips-2019-deep-learning/), "one of the three pioneers of deep learning") have identified with the system 1 vs system 2 dichotomy, noting the need for the more meta-cognizant, exact, and deliberate (if slow) characteristic of system 2 to complement the fluid and opaque decisions being made by current technologies.

Somewhat recently Meta (then facebook) AI labs presented a model capable of solving many of the same problems as computer algebra systems like wolfram mathematica, maple, and matlab (check this one). Algebra is very much a system 2 task, requiring slow and methodological action. Manipulation of symbols is often described as a system 2 task. The AI operates on the symbolic equation (as opposed to numerically solving it), using similar methods to translation models. Unlike you or me, it learns statistical patterns from large sets of equation-solution pairs. This makes it faster than normal computer algebra systems, but also allows it to have learned approximate ( and thus potentially wrong, which it did) patterns. Normal computer algebra systems have no such issue. 

It can be easy to mistake a symbol for the thing itself. We need to keep in mind that it represents *something*. It has its own rules, and unique properties that a symbol can obfuscate. When we work at the symbolic level, and only the symbolic level,[![We can easily prove 1=2](https://www.youtube.com/watch?v=hI9CaQD7P6I)](https://www.youtube.com/watch?v=hI9CaQD7P6I). Symbols are not enough.  

Given a photo of a canine, you could tell if it was a wolf or a dog in the image. Maybe you’d decide based on snout shape, or fur color. You’ll likely have a list of criteria along with a sort of “I know it when I see it” intuition. The former we can associate with system 2 and the latter with system 1. We can train a model to distinguish dogs from wolves as well. It can achieve greater than 90% accuracy. It could outperform most humans. But what it can learn is that a white patch in the image means it should categorize it as a wolf. I need to say, it’s not the presence of snow, but simply the prevalence of white pixels irrespective of whatever other features exist in the image. It’s not learning a correlation so much as an incorrect rule. A fully white image is not a picture of a wolf. But to this model, it is, because most of the wolf images it saw had snow and thus a prevalence of white pixels, because of how humans tend to photograph wolves. This is the [![short-cut principle](https://arxiv.org/abs/2004.07780)](https://arxiv.org/abs/2004.07780) : a model will learn the quickest, least expensive rule that leads to the best accuracy given the data it has seen. 


| ![Husky vs. Wolf]({{ "/assets/images/firstBlog/aiSnow.png" | relative_url }})|
|:--:|
| *An Ai's explanation of why this is a wolf*  [![Ethical Machine Learning](https://www.researchgate.net/publication/329277474_Can_Everyday_AI_be_Ethical_Machine_Learning_Algorithm_Fairness_english_version)](https://www.researchgate.net/publication/329277474_Can_Everyday_AI_be_Ethical_Machine_Learning_Algorithm_Fairness_english_version)    |

Maybe you don’t care, getting a wolf vs a dog wrong won’t change your life. However these models are being deployed right now. They’re used to determine loan approval. They were already used to determine [![parole](https://www.technologyreview.com/2019/01/21/137783/algorithms-criminal-justice-ai/)](https://www.technologyreview.com/2019/01/21/137783/algorithms-criminal-justice-ai/). They’re proposed to detect cancer in x-rays, and grade student essays. These flaws make them vulnerable to attackers, who can discover and then exploit these short-cut rules and oddities.

While the goal of mimicking the system 1 and 2 dichotomy will likely be helpful in further advancing deep learning, it alone won’t be enough. Contextual awareness is deeply lacking in deep learning models, as is objectness bias (that is the tendency to organize the world into objects, instead of say atoms) which are clearly unconscious system 1 behaviors. Further system 2’s attention is focused, deliberate, and singular. It does not allow for the broad, and open attention needed for many tasks or fully understanding context. Worse yet, the symbol focused rationalistic system 2 can find itself losing what the symbol actually represents. Much of what we want from deep learning models is the automation of behaviors attributable to system 1, like driving. 

While the interplay between system 1 and 2 is desirable, with system 2 working as a teacher and exception handler for system 1, many of the issues with AI we currently have won’t be solved by it because many of the issues we have with deep learning require not just a better system 2 (deliberate) but also a better  system 1 (intuitive). It lacks the ability to properly explain many of the issues we currently see in AI, and even carries potential harm in learning the wrong symbolic logic (the trite example where an AI learns to maximize human happiness by killing us all). It is a useful abstraction, but it is simply not enough.

## Left and Right Brain

An appealing alternative can be found in the more neurologically grounded right-left brain dichotomy.  Unfortunately there are many misconceptions of left-right brain dichotomy as it has leaked into pop-science. Let’s cover these now and clear things up. Because of this misconception the left brain is considered to be somewhat cold, logical, and rational whereas the right is seen as creative, emotional, and non-linguistic. This is not precisely untrue, but leads to incorrect conclusions. While broadly the left hemisphere deals with the grammar and mechanics of language, the right is used to understand the meaning and context of language. The ability to understand metaphors, thought to be fundamental to human cognition and often deeply lacking in deep learning models, is a right hemisphere task. Both hemispheres play a role in tasks like mathematics, where the left manipulates symbols and right searches for understanding of the underlying structure. People (and for that matter animals) use both hemispheres, for their respective strengths, to accomplish many goals. There is no being left or right brained.  So far, it might be easy to identify the left hemisphere with system 2 and the right with system 1. 

Doing so would be a mistake. Somewhat boring tasks like seeing how far an object is, are attributed to [![system 2]( https://www.scientificamerican.com/article/kahneman-excerpt-thinking-fast-and-slow/ )]( https://www.scientificamerican.com/article/kahneman-excerpt-thinking-fast-and-slow/ ) which is associated with the [![left hemisphere](https://www.diffen.com/difference/Left_Brain_vs_Right_Brain )](https://www.diffen.com/difference/Left_Brain_vs_Right_Brain ). Both hemispheres are mixtures of system 1 and system 2, other things, and have attributes that have no real bearing on the Kahnmna’s system at all.  More informative are the peculiarities (and sometimes failure modes) of the two hemispheres. The left can lose detail in and become overly attached to its categorizations. It can overgeneralize into caricatures. It can be unaware of what it does not know. It has a detailed but narrow focus. It sees and uses tools, and operates in an internal model of the world. The right has a broad holistic view of the world. It understands context. It is observational. It sees the world as new, and things as unique wholes. While the left has language, the right could be said to communicate in art, particularly when depicting that which we have no words for yet. The left deals with what is known, and the right with exploration.

| Left |	Right |
| ----------- | ----------- |
| Representation | 	Perception |
| The Abstract | 	The Concrete |
| Narrow focus  |	Broad focus |
| Language | 	Embodiment |
| Manipulation | 	Experience (?) |
| Parts | 	Wholes |
| Machines | 	Life |
| The Static |	The Changing |
| Focus on the known | 	Alertness for the novel |
| Consistency, familiarity, prediction | 	Contradiction, novelty, surprise |
 | A closed knowledge system |	An open knowledge system |
| (Urge after) Consistency |	(Urge after) Completeness |
| The Known |	The Unknown, The ineffable |
| The explicit | 	The implicit |
| Generalisation | 	Individuality/uniqueness |
| Particulars | 	Context |

[![Table adapted from](https://mindhacks.com/2013/02/23/the-master-and-his-emissary/)](https://mindhacks.com/2013/02/23/the-master-and-his-emissary/)

While both are necessary, damage to the right hemisphere (and thus reducing its qualities from someone’s experience of the world and future behavior) can be far more detrimental to someone than damage to the left. This can be explored in people with strokes damaging primarily a single hemisphere.

| ![Right hemisphere stroke]({{ "/assets/images/firstBlog/stroke.png" | relative_url }})|
|:--:|
| *Three images by artist Reynold Brown after a right hemisphere stroke. The left side ( associated with the right hemisphere) is neglected and while parts are generally correct, their correspondence to each other is wrong or distorted. There is an overt ignorance of the left visual field (associated with the right hemisphere) which can be seen even more clearly in the image below. *  [![Assoicated Paper](https://www.semanticscholar.org/paper/Painting-after-right-hemisphere-stroke-case-studies-B%C3%A4zner-Hennerici/5ce8748d9f4fed49ca82d67042b8f18913d3ef92)](https://www.semanticscholar.org/paper/Painting-after-right-hemisphere-stroke-case-studies-B%C3%A4zner-Hennerici/5ce8748d9f4fed49ca82d67042b8f18913d3ef92)    |

| ![Right hemisphere stroke]({{ "/assets/images/firstBlog/clock.png" | relative_url }})|
|:--:|
| *A clock draw by someone with a right hemisphere stroke*    |

| ![Right hemisphere stroke]({{ "/assets/images/firstBlog/recon.png" | relative_url }})|
|:--:|
| *Two left hemisphere patients attempt to reconstruct A in B and C*  [![Assoicated Paper](https://www.sciencedirect.com/topics/medicine-and-dentistry/constructional-apraxia)](https://www.sciencedirect.com/topics/medicine-and-dentistry/constructional-apraxia)    |

The left hemisphere can get the parts right, but not the whole. It doesn’t understand context. It categorizes objects, but loses their particularity in the process. It can see in sharp but narrow detail. It has language, but can construct totally fictitious stories it nevertheless   [![shows every appearance of believing](https://web.archive.org/web/20181215020736/https://courses.dce.harvard.edu/~phils4/splitbrain.pdf)](https://web.archive.org/web/20181215020736/https://courses.dce.harvard.edu/~phils4/splitbrain.pdf). Now, this is necessarily a brief, simplified, and abstract model of the differences between the left and right brain. Still, it serves to show its peculiarities, which are often mirrored in deep learning models. 

Now we can look back at what artifacts state-of-the-art art-generation models produce, and have from the very beginning. Even in the very first video
 <blockquote class="twitter-tweet"><p lang="en" dir="ltr">This was made using the DALLE-2 neural network to extend Michaelangelo&#39;s creation of Adam. <a href="https://t.co/sIfTEjXgwO">pic.twitter.com/sIfTEjXgwO</a></p>&mdash; Far Left Kyle (@FLKDayton) <a href="https://twitter.com/FLKDayton/status/1543261364315193346?ref_src=twsrc%5Etfw">July 2, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  
we can see a local breakdown of things. A face will seamlessly blend into the background, or otherwise warp and dissolve. A hand begins and then stops. It’s not just becoming something else, it stops being. It’s not a hand as you see it. It’s a vague part divorced from the whole. It is a simulacra. 

This may mean that the current trend of larger and larger models on more and more data may not be enough. As always the kind of data is deeply relevant. Language being a relatively left hemisphere phenomenon, with its tendency to categorize and label things with a word (and to then ignore the uniqueness of the object), necessarily biases linguistic data. Language is a broad tool, and while it encapsulates much of human experience (particularly in our day-to-day) it does not capture all of it. Symbols are not enough. Even something impressive like facebooks algebraic solver is not exactly correct; it learns a what, but not necessarily a how/why. And so while it can do something very system 2, this abstract manipulation of symbols, it’s an odd kind of approximation, working only in the symbol space without knowing what the symbols mean. By the short cut principle, this is always going to be the issue. 
Humans, in their deliberate thought, can come up with the wrong pattern or [![find a pattern in noise](https://escholarship.org/content/qt5qb6915t/qt5qb6915t.pdf)](https://escholarship.org/content/qt5qb6915t/qt5qb6915t.pdf).

Even more than that we don’t have a mechanism to enforce objectness in these models. They could find all the parts but have no way to put them all together. Without a meaningful idea of what something is, these AI’s can perform all sorts of tasks within an acceptable margin of error. But only when in an already known space. Anything outside of that range, we still see collapse. We only get better at making parts. A whole is needed in order to have a model that is safe and generalizable. We need to utilize and engineer right-brain features so that these models can incorporate a whole context. Without it we can expect to consistently need humans in the loop to ensure things are being treated in a reasonable and common sense fashion. 

| ![Oleg Shuplyak, the painter who hides faces in landscape]({{ "/assets/images/firstBlog/oleg.png" | relative_url }}){: width="250" }|
|:--:|
| *A painting by Oleg Shuplyak, can you say what exactly this is?*  |

| ![duck rabbit]({{ "/assets/images/firstBlog/rab.png" | relative_url }}){: width="250" }|
|:--:|
| *Or what this is?*  |

| ![Open AI CLIP apple]({{ "/assets/images/firstBlog/clip.png" | relative_url }})|
|:--:|
| *Because Open AI's clip (the model powering many modern art generation systems) cannot*  [![Assoicated Paper](https://openai.com/blog/multimodal-neurons/)](https://openai.com/blog/multimodal-neurons/)    |

##Conclusion

But the goal of AI is automation, removing humans from the loop. These systems will consistently be deployed without oversight, enforcing rules while quietly doing harm. Analogising with the human mind and brain (as well as mammalian) helps to move us in the right direction, finding the peculiarities of deep learning. They can inspire new methods. Keeping in mind system 1 and 2 helps in AI engineering, either in architecture or safety barriers. But it lacks the explainability that the left-right brain dichotomy can provide. They can both provide meaningful insights and help in making decisions. There are many more relevant dichotomies: high vs low resolution, continuous vs discrete, supervised vs unsupervised, interpolation vs extrapolation, etc. each covering a different aspect of reality and learning.  We can’t expect any single dichotomy to provide a full prescription of what it is to be aware and intelligent, but each does have something valuable to add. Increasing awareness and comparisons to the left-right dichotomy can help increase real performance of these models and prevent the catastrophic harm they can cause. In future articles I'll cover some mathematical tooling we can use to better instaiate right hemisphere behaviour, in particular objectness. 


<!--more-->
